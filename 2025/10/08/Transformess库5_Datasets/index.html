

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/MyBlog/img/fluid.png">
  <link rel="icon" href="/MyBlog/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="云端fff">
  <meta name="keywords" content="技术,编程,生活,博客">
  
    <meta name="description" content="datasets 是一个简单易用的数据集加载库，可方便地从本地或 HF hub 加载数据集，并完成数据划分、清洗、数据集和加载器构造等工作">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformess库（5）—— Datasets">
<meta property="og:url" content="https://wxc971231.github.io/MyBlog/2025/10/08/Transformess%E5%BA%935_Datasets/index.html">
<meta property="og:site_name" content="云端fff的博客">
<meta property="og:description" content="datasets 是一个简单易用的数据集加载库，可方便地从本地或 HF hub 加载数据集，并完成数据划分、清洗、数据集和加载器构造等工作">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wxc971231.github.io/MyBlog/img/Transformers%E5%BA%935_Datasets/Transformers.png">
<meta property="article:published_time" content="2025-10-08T19:03:03.000Z">
<meta property="article:modified_time" content="2025-10-16T02:40:02.123Z">
<meta property="article:author" content="云端fff">
<meta property="article:tag" content="Transformers库">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://wxc971231.github.io/MyBlog/img/Transformers%E5%BA%935_Datasets/Transformers.png">
  
  
  
  <title>Transformess库（5）—— Datasets - 云端fff的博客</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.16.2/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/MyBlog/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/MyBlog/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/MyBlog/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/MyBlog/css/iconfont/iconfont.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"wxc971231.github.io","root":"/MyBlog/","version":"1.9.8","typing":{"enable":true,"typeSpeed":50,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":6},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/MyBlog/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/MyBlog/js/utils.js" ></script>
  <script  src="/MyBlog/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/MyBlog/">
      <strong>云端FFF的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/MyBlog/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/MyBlog/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/MyBlog/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/MyBlog/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/MyBlog/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/MyBlog/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Transformess库（5）—— Datasets"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-08 19:03" pubdate>
          2025年10月8日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.5k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          55 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Transformess库（5）—— Datasets</h1>
            
            
              <div class="markdown-body">
                
                <ul>
<li>首发链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/wxc971231/article/details/152643840">Transformess库（5）—— Datasets</a></li>
<li>Hugging Face 是一家在 AI 领域具有重要影响力的科技公司，他们的开源工具和社区建设为NLP研究和开发提供了强大的支持。它们拥有当前最活跃、最受关注、影响力最大的 <a target="_blank" rel="noopener" href="https://huggingface.co/">NLP 社区</a>，最新最强的 NLP 模型大多在这里发布和开源。该社区也提供了丰富的教程、文档和示例代码，帮助用户快速上手并深入理解各类 Transformer 模型和 NLP 技术</li>
<li>Transformers 库是 Hugging Face 最著名的贡献之一，它最初是 Transformer 模型的 pytorch 复现库，随着不断建设，至今已经成为 NLP 领域最重要，影响最大的基础设施之一。该库提供了大量预训练的模型，涵盖了多种语言和任务，成为当今大模型工程实现的主流标准，换句话说，<strong>如果你正在开发一个大模型，那么按 Transformer 库的代码格式进行工程实现、将 check point 打包成 hugging face 格式开源到社区，对于推广你的工作有很大的助力作用</strong>。本系列文章将介绍 Transformers 库的基本使用方法</li>
<li>参考：
<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/index">官方教程</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1KM4y1q7Js">手把手带你实战HuggingFace Transformers</a></li>
</ul>
</li>
</ul>
<hr />
<ul>
<li>datasets 是一个简单易用的数据集加载库，可方便地从本地或 hugging face hub 加载数据集
<ul>
<li>开源数据集列表：<a target="_blank" rel="noopener" href="https://huggingface.co/datasets">https://huggingface.co/datasets</a></li>
<li>文档地址：<a target="_blank" rel="noopener" href="https://huggingface.co/docs/datasets/index">https://huggingface.co/docs/datasets/index</a></li>
</ul>
</li>
<li>无论自定义还是从 Hugging Face Hud 下载，Transformers 库中的数据集 (Dataset) 是一个包含以下内容的目录：
<ol>
<li><strong>一些通用格式数据文件</strong>（如 JSON、CSV、Parquet、文本文件等）</li>
<li><strong>一个数据加载脚本</strong>，它定义一个 <code>datasets.GeneratorBasedBuilder</code>，用于从数据文件构造最终程序使用的 <code>datasets.arrow_dataset.Dataset</code> 对象。Transformers 库默认调研各类型文件的通用数据加载脚本，遇到以下复杂情况时则需自定义
<table>
<thead>
<tr>
<th>情况</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>复杂的数据结构</td>
<td>如嵌套的 JSON、特殊格式</td>
</tr>
<tr>
<td>多文件组合</td>
<td>需要从多个文件中组合数据</td>
</tr>
<tr>
<td>特殊预处理</td>
<td>需要在加载时进行数据清洗或转换</td>
</tr>
<tr>
<td>自定义字段映射</td>
<td>原始数据字段与期望格式不匹配</td>
</tr>
</tbody>
</table>
</li>
</ol>
</li>
</ul>
<h1 id="1-datasets-的基本使用"><a class="markdownIt-Anchor" href="#1-datasets-的基本使用"></a> 1. Datasets 的基本使用</h1>
<h2 id="11-加载在线数据集"><a class="markdownIt-Anchor" href="#11-加载在线数据集"></a> 1.1 加载在线数据集</h2>
<ul>
<li>
<p>使用 <code>datasets.load.load_dataset</code> 方法，可直接从 HF Hub 下载 <code>path</code> 形参指定的在线开源数据集</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> *<br>datasets = load_dataset(path=<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>)<br>datasets<br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 5850<br>    &#125;)<br>    validation: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 1679<br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>
<p>注意到在线数据集通常已进行划分并以字典形式呈现。可以传入 <code>split</code> 参数直接加载指定划分，且能通过切片方式加载指定数据</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 只加载训练集</span><br>dataset = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br><br><span class="hljs-comment"># 用切片方式，只加载训练集的前100条数据</span><br>dataset = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>, split=<span class="hljs-string">&quot;train[:100]&quot;</span>)  <br><br><span class="hljs-comment"># 以列表形式加载多个数据集</span><br>dataset = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>, split=[<span class="hljs-string">&quot;train[50%:]&quot;</span>, <span class="hljs-string">&quot;train[:50%]&quot;</span>, <span class="hljs-string">&quot;validation[10:20]&quot;</span>])  <br></code></pre></td></tr></table></figure>
</li>
<li>
<p>有些数据集是多任务数据集，它们包含多个子任务，需要通过 <code>name</code> 形参指定加载哪个任务的数据。例如</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 错误的用法</span><br>super_glue_datasets = load_dataset(path=<span class="hljs-string">&quot;super_glue&quot;</span>)  <span class="hljs-comment"># ❌ 会报错</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">ValueError: Config name is missing.</span><br><span class="hljs-string">Please pick one among the available configs: [&#x27;axb&#x27;, &#x27;axg&#x27;, &#x27;boolq&#x27;, &#x27;cb&#x27;, &#x27;copa&#x27;, &#x27;multirc&#x27;, &#x27;record&#x27;, &#x27;rte&#x27;, &#x27;wic&#x27;, &#x27;wsc&#x27;, &#x27;wsc.fixed&#x27;]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># 正确的用法 - 指定具体任务</span><br>boolq_dataset = load_dataset(<span class="hljs-string">&quot;super_glue&quot;</span>, name=<span class="hljs-string">&quot;boolq&quot;</span>, trust_remote_code=<span class="hljs-literal">True</span>)    <span class="hljs-comment"># 布尔问答</span><br>copa_dataset = load_dataset(<span class="hljs-string">&quot;super_glue&quot;</span>, name=<span class="hljs-string">&quot;copa&quot;</span>, trust_remote_code=<span class="hljs-literal">True</span>)        <span class="hljs-comment"># 因果推理</span><br></code></pre></td></tr></table></figure>
<p>其中 <code>trust_remote_code=True</code> 代表使用 HF Hub 开源数据集自定义的数据集脚本</p>
</li>
<li>
<p>数据集、模型等默认下载到 <code>HF_HOME</code> 和 <code>HUGGINGFACE_HUB_CACHE</code> 等全局变量指定位置，可以调整</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 全局设置存储目录</span><br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&#x27;HF_HOME&#x27;</span>] = <span class="hljs-string">r&#x27;D:\Programmer\HuggingFace&#x27;</span><br>os.environ[<span class="hljs-string">&#x27;HUGGINGFACE_HUB_CACHE&#x27;</span>] = <span class="hljs-string">r&#x27;D:\Programmer\HuggingFace\Hub&#x27;</span><br><br><span class="hljs-comment"># 在下载时指定存储目录</span><br>datasets = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>, cache_dir=<span class="hljs-string">&quot;D:/MyDatasets/cache&quot;</span>)<br><br><span class="hljs-comment"># 详细配置下载行为</span><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> DownloadConfig<br>download_config = DownloadConfig(    <span class="hljs-comment"># 创建下载配置</span><br>    cache_dir=<span class="hljs-string">&quot;D:/MyDatasets/cache&quot;</span>,<br>    force_download=<span class="hljs-literal">False</span>,              <span class="hljs-comment"># 是否强制重新下载</span><br>    resume_download=<span class="hljs-literal">True</span>,              <span class="hljs-comment"># 是否支持断点续传</span><br>)<br>datasets = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>, download_config=download_config)<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="12-查看数据集"><a class="markdownIt-Anchor" href="#12-查看数据集"></a> 1.2 查看数据集</h2>
<ul>
<li>数据通常以 <code>Dict[str, list]</code> 的字典形式保存，支持通过切片形式访问  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 加载数据</span><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> *<br>datasets = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>)<br><br><span class="hljs-comment"># 支持切片形式访问，字典形式（元素为列表）返回</span><br>datasets[<span class="hljs-string">&#x27;train&#x27;</span>][:<span class="hljs-number">2</span>]   <br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">&#123;</span><br><span class="hljs-string">    &#x27;title&#x27;: [&#x27;望海楼美国打“台湾牌”是危险的赌博&#x27;, &#x27;大力推进高校治理能力建设&#x27;],</span><br><span class="hljs-string">    &#x27;content&#x27;: [&#x27;近期，美国国会众院通过法案...&#x27;, &#x27;在推进“双一流”高校建设进程中...&#x27;]</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># 按字段访问，便于做 batch tokenize</span><br>datasets[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-string">&#x27;title&#x27;</span>][:<span class="hljs-number">2</span>]  <br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">[&#x27;望海楼美国打“台湾牌”是危险的赌博&#x27;, &#x27;大力推进高校治理能力建设&#x27;]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># 获取字段名和datasets.features.features.Features 对象</span><br><span class="hljs-built_in">print</span>(datasets[<span class="hljs-string">&#x27;train&#x27;</span>].column_names)   <span class="hljs-comment"># [&#x27;title&#x27;, &#x27;content&#x27;]</span><br><span class="hljs-built_in">print</span>(datasets[<span class="hljs-string">&#x27;train&#x27;</span>].features)       <span class="hljs-comment"># &#123;&#x27;title&#x27;: Value(dtype=&#x27;string&#x27;, id=None), &#x27;content&#x27;: Value(dtype=&#x27;string&#x27;, id=None)&#125;</span><br></code></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="13-划分数据集"><a class="markdownIt-Anchor" href="#13-划分数据集"></a> 1.3 划分数据集</h2>
<ul>
<li>有些数据集未进行原始划分或划分不满足要求，这时可以使用 <code>dataset.train_test_split</code> 方法进行划分。<strong>对任意 <code>Dataset</code> 对象调用此方法，会返回一个由 train 和 test 构成的 <code>DatasetDict</code></strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">datasets = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>)<br>dataset = datasets[<span class="hljs-string">&#x27;train&#x27;</span>]<br><br><span class="hljs-comment"># 将原本的 &#x27;train&#x27; 数据集再次按比例划分，10%做测试集，90%做训练集</span><br>final_datasets = dataset.train_test_split(test_size=<span class="hljs-number">0.1</span>) <br>final_datasets<br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 5265<br>    &#125;)<br>    test: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 585<br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
<li>下例演示如何将 &quot;madao33/new-title-chinese&quot; 的 train 数据集重新划分为 train、test、valid 三部分  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">datasets = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>)<br>dataset = datasets[<span class="hljs-string">&#x27;train&#x27;</span>]<br><br><span class="hljs-comment"># 先划分出训练集，train 占 80%</span><br>train_test = dataset.train_test_split(test_size=<span class="hljs-number">0.2</span>)<br><span class="hljs-comment"># 把占 20% 的 test 对半分，作为 test 和 valid</span><br>test_val = train_test[<span class="hljs-string">&#x27;test&#x27;</span>].train_test_split(test_size=<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># 重新组织数据集</span><br>final_datasets = DatasetDict(&#123;<br>    <span class="hljs-string">&#x27;train&#x27;</span>: train_test[<span class="hljs-string">&#x27;train&#x27;</span>],      <span class="hljs-comment"># 80%</span><br>    <span class="hljs-string">&#x27;test&#x27;</span>: test_val[<span class="hljs-string">&#x27;train&#x27;</span>],         <span class="hljs-comment"># 10%</span><br>    <span class="hljs-string">&#x27;validation&#x27;</span>: test_val[<span class="hljs-string">&#x27;test&#x27;</span>]     <span class="hljs-comment"># 10%</span><br>&#125;)<br>final_datasets<br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 4680<br>    &#125;)<br>    test: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 585<br>    &#125;)<br>    validation: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 585<br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
<li>如果只是为了划分数据，用 1.1 节介绍的切分加载形式也能做到， <code>dataset.train_test_split</code> 方法的意义在于其可以进行更精细的控制。例如<strong>对二分类任务数据集 BoolQ 来说，我们希望划分后的 train 和 test 都具有相同的正负样本比例，这就需要设置 <code>stratify_by_column</code> 对指定列（标签）进行分层采样</strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># super_glue 是一个多任务数据集合，只加载其中 boolq 任务的数据</span><br>boolq_dataset = load_dataset(<span class="hljs-string">&quot;super_glue&quot;</span>, <span class="hljs-string">&quot;boolq&quot;</span>, trust_remote_code=<span class="hljs-literal">True</span>) <br>dataset = boolq_dataset[<span class="hljs-string">&#x27;train&#x27;</span>]<br><br><span class="hljs-comment"># 按比例划分，同时确保给定字段 &#x27;label&#x27; 的取值在数据集中是均衡的</span><br>final_datasets = dataset.train_test_split(test_size=<span class="hljs-number">0.1</span>, stratify_by_column=<span class="hljs-string">&#x27;label&#x27;</span>) <br>final_datasets<br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 4680<br>    &#125;)<br>    test: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 585<br>    &#125;)<br>    validation: Dataset(&#123;<br>        features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>        num_rows: 585<br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="14-数据选取-过滤和打乱"><a class="markdownIt-Anchor" href="#14-数据选取-过滤和打乱"></a> 1.4 数据选取、过滤和打乱</h2>
<ul>
<li>前文 1.2 节说明了可以通过切片方式查看数据，注意其会返回普通 python 字典或列表  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> *<br>datasets = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>)<br><br><span class="hljs-comment"># 支持切片形式访问，字典形式（元素为列表）返回</span><br>datasets[<span class="hljs-string">&#x27;train&#x27;</span>][:<span class="hljs-number">2</span>]   <br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">&#123;</span><br><span class="hljs-string">    &#x27;title&#x27;: [&#x27;望海楼美国打“台湾牌”是危险的赌博&#x27;, &#x27;大力推进高校治理能力建设&#x27;],</span><br><span class="hljs-string">    &#x27;content&#x27;: [&#x27;近期，美国国会众院通过法案...&#x27;, &#x27;在推进“双一流”高校建设进程中...&#x27;]</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure>
以上方式适合快速查看数据，但有时我们想获取一个子数据集对象，类似 1.1 节切片加载的效果。这时可以<strong>使用 <code>dataset.select()</code> 方法，这会通过索引引用方式创建新的 Dataset 对象，从而保持所有 Dataset 的方法和属性</strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br><br><span class="hljs-comment"># 取给定索引位置的样本，创建新 datset 对象（注意和 datasets[&#x27;train&#x27;][:2] 这种查看方式不同，后者不创建 dataset 对象）</span><br>dataset.select([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>])   <br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">Dataset(&#123;<br>    features: [&#x27;title&#x27;, &#x27;content&#x27;],<br>    num_rows: 2<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
<li>在数据预处理时，通常需要从大数据集中筛选出符合特定条件的高质量数据，这时<strong>可用 <code>dataset.filter()</code> 方法返回符合条件数据构成的数据集对象</strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br>    <br><span class="hljs-comment"># 使用 lambda 函数作为条件，过滤数据集（这个不是in-place的）</span><br>filter_dataset = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> example: <span class="hljs-string">&quot;中国&quot;</span> <span class="hljs-keyword">in</span> example[<span class="hljs-string">&#x27;title&#x27;</span>])  <br>filter_dataset[<span class="hljs-string">&#x27;title&#x27;</span>][:<span class="hljs-number">5</span>]<br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[&#x27;聚焦两会，世界探寻中国成功秘诀&#x27;,<br> &#x27;望海楼中国经济的信心来自哪里&#x27;,<br> &#x27;“中国奇迹”助力世界减贫跑出加速度&#x27;,<br> &#x27;和音瞩目历史交汇点上的中国&#x27;,<br> &#x27;中国风采感染世界&#x27;]<br></code></pre></td></tr></table></figure>
可通过批处理或多进程方式提高性能  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br><br><span class="hljs-comment"># 对于大数据集，可以使用批处理模式提高效率</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">batch_filter_function</span>(<span class="hljs-params">examples</span>):<br>    <span class="hljs-keyword">return</span> [<span class="hljs-string">&quot;中国&quot;</span> <span class="hljs-keyword">in</span> title <span class="hljs-keyword">for</span> title <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&#x27;title&#x27;</span>]]<br>filtered_dataset = dataset.<span class="hljs-built_in">filter</span>(batch_filter_function, batched=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 即使处理方法不支持 batch 计算，还可以用多进程加速</span><br>filtered_dataset = dataset.<span class="hljs-built_in">filter</span>(<br>    <span class="hljs-keyword">lambda</span> x: <span class="hljs-string">&quot;中国&quot;</span> <span class="hljs-keyword">in</span> x[<span class="hljs-string">&#x27;title&#x27;</span>],<br>    num_proc=<span class="hljs-number">4</span>  <span class="hljs-comment"># 使用4个进程</span><br>)<br></code></pre></td></tr></table></figure>
</li>
<li><strong>使用 <code>Dataset.shuffle()</code> 可以简单地打乱数据集</strong>，通过链接 Dataset.shuffle() 和 Dataset.select() 函数可以快速创建一个随机的数据子集  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset.shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="15-数据映射"><a class="markdownIt-Anchor" href="#15-数据映射"></a> 1.5 数据映射</h2>
<ul>
<li><code>dataset.map()</code> 是 Hugging Face Datasets 库中最重要的 数据转换方法 ，用于<strong>对数据集中的每个样本应用自定义的处理函数</strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br><br><span class="hljs-comment"># 数据映射.map方法支持我们定义一个样本处理函数，使用它处理数据集中的每一个样本</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_prefix</span>(<span class="hljs-params">example</span>):<br>    example[<span class="hljs-string">&#x27;title&#x27;</span>] = <span class="hljs-string">&quot;Prefix: &quot;</span> + example[<span class="hljs-string">&#x27;title&#x27;</span>]<br>    <span class="hljs-keyword">return</span> example<br>    <br>prefix_datset = dataset.<span class="hljs-built_in">map</span>(add_prefix)<br>prefix_datset[:<span class="hljs-number">2</span>][<span class="hljs-string">&#x27;title&#x27;</span>]<br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[&#x27;Prefix: 望海楼美国打“台湾牌”是危险的赌博&#x27;,<br>&#x27;Prefix: 大力推进高校治理能力建设&#x27;,]<br></code></pre></td></tr></table></figure>
</li>
<li><strong><code>dataset.map()</code> 主要用于配合 tokenizer 完成高效的数据预处理</strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数据映射功能主要是结合 tokenizer 使用的，方便进行数据预处理</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> *<br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-chinese&quot;</span>)<br>datasets = load_dataset(<span class="hljs-string">&quot;madao33/new-title-chinese&quot;</span>)    <br><br><span class="hljs-comment"># 利用 map 方法处理 DatasetDict 中各数据集的所有数据</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">example, tokenizer</span>):<br>    model_inputs = tokenizer(example[<span class="hljs-string">&quot;content&quot;</span>], max_length=<span class="hljs-number">512</span>, truncation=<span class="hljs-literal">True</span>)<br>    labels = tokenizer(example[<span class="hljs-string">&quot;title&quot;</span>], max_length=<span class="hljs-number">32</span>, truncation=<span class="hljs-literal">True</span>)<br>    model_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = labels[<span class="hljs-string">&quot;input_ids&quot;</span>]    <span class="hljs-comment"># 摘要任务，title 的编码结果作为 label</span><br>    <span class="hljs-keyword">return</span> model_inputs<br><br>processed_dataset = datasets.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> example: preprocess_function(example, tokenizer))<br>processed_dataset   <span class="hljs-comment"># 处理后的数据集中增加了 &#x27;input_ids&#x27;, &#x27;token_type_ids&#x27;, &#x27;attention_mask&#x27;, &#x27;labels&#x27; 等字段</span><br></code></pre></td></tr></table></figure>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;content&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>],<br>        num_rows: <span class="hljs-number">5850</span><br>    &#125;)<br>    validation: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;content&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>],<br>        num_rows: <span class="hljs-number">1679</span><br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
<li>可通过批处理或多进程方式提升效率  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 调用 .map() 方法时设置 batched=True 启动批量处理</span><br><span class="hljs-comment"># 以上 preprocess_function 只做了 tokenize，当 Tokenizer 有 fast 实现时，以 batch 形式进行处理会更快</span><br>processed_dataset = datasets.<span class="hljs-built_in">map</span>(<br>    <span class="hljs-keyword">lambda</span> examples: preprocess_function(examples, tokenizer),<br>    batched=<span class="hljs-literal">True</span><br>)<br><br><span class="hljs-comment"># 调用 .map() 方法时设置 num_proc=n 启动多进程处理</span><br><span class="hljs-comment"># 当处理方法 preprocess_function 内含有不支持 batch 的方法时，还可以用多进程加速</span><br><span class="hljs-comment"># 这里需注意使用 partial，否则子进程无法访问在主进程中定义的 preprocess_function 函数，除非 preprocess_function 定义为全局函数，无需传入 example 以外的参数</span><br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> partial<br>processed_dataset = datasets.<span class="hljs-built_in">map</span>(<br>    partial(preprocess_function, tokenizer=tokenizer),<br>    num_proc=<span class="hljs-number">4</span><br>)<br></code></pre></td></tr></table></figure>
</li>
<li>调用 <code>dataset.map()</code> 方法时，可<strong>在 <code>remove_columns</code> 参数中设置要去除的字段列表</strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 调用 .map() 方法时，在 remove_columns 参数中设置要去除的字段列表</span><br><span class="hljs-comment"># 常用此方式去除数据的原始字段</span><br>processed_datasets = datasets.<span class="hljs-built_in">map</span>(<br>    <span class="hljs-keyword">lambda</span> example: preprocess_function(example, tokenizer), <br>    batched=<span class="hljs-literal">True</span>, <br>    remove_columns=datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names<br>)<br>processed_datasets<br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [&#x27;input_ids&#x27;, &#x27;token_type_ids&#x27;, &#x27;attention_mask&#x27;, &#x27;labels&#x27;],<br>        num_rows: 5850<br>    &#125;)<br>    validation: Dataset(&#123;<br>        features: [&#x27;input_ids&#x27;, &#x27;token_type_ids&#x27;, &#x27;attention_mask&#x27;, &#x27;labels&#x27;],<br>        num_rows: 1679<br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="16-数据集的本地保存和加载"><a class="markdownIt-Anchor" href="#16-数据集的本地保存和加载"></a> 1.6 数据集的本地保存和加载</h2>
<ul>
<li>
<p>1.5 节中数据处理往往很耗时，可以用 <code>dataset.save_to_disk</code> 和 <code>dataset.load_from_disk</code> 直接把处理好的 <code>DatasetDict</code> 序列化保存到本地，或从本地加载使用</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 保存到指定路径</span><br>processed_datasets.save_to_disk(<span class="hljs-string">&#x27;./saved/processed_datasets&#x27;</span>)<br><span class="hljs-comment"># 从本地加载</span><br>processed_datasets = load_from_disk(<span class="hljs-string">&quot;./saved/processed_datasets&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>这会在指定路径创建具有以下结构的目录：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">processed_datasets/<br>├── dataset_dict.json<br>├── train<br>│   ├── data-<span class="hljs-number">00000</span>-of-<span class="hljs-number">00001.</span>arrow<br>│   ├── dataset_info.json<br>│   └── state.json<br>└── validation<br>    ├── data-<span class="hljs-number">00000</span>-of-<span class="hljs-number">00001.</span>arrow<br>    ├── dataset_info.json<br>    └── state.json<br></code></pre></td></tr></table></figure>
<p>注意到每个部分都有 <code>.arrow</code> 表以及保存元数据的 <code>dataset_info.json</code> 和 <code>state.json</code> 。<strong>可以将 Arrow 格式视为一个优化过的列和行的精美表格，它针对构建处理和传输大型数据集的高性能应用程序进行了优化</strong></p>
</li>
<li>
<p>此外，还可以将数据保存为 csv 或 json 格式。这时我们必须将每个部分存储为单独的文件，一种方法是遍历 DatasetDict 中的键和值</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 这将把每个部分保存为 JSON Lines格式 ，其中数据集中的每一行都存储为一行 JSON</span><br><span class="hljs-keyword">for</span> split, dataset <span class="hljs-keyword">in</span> processed_dataset.items():<br>    dataset.to_json(<span class="hljs-string">f&quot;./saved/processed_json/<span class="hljs-subst">&#123;split&#125;</span>.jsonl&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>使用下文 2.1 节所述方法直接加载多个 json 文件</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">data_files = &#123;<br>    <span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;./saved/processed_json/train.jsonl&quot;</span>,<br>    <span class="hljs-string">&quot;validation&quot;</span>: <span class="hljs-string">&quot;./saved/processed_json/validation.jsonl&quot;</span>,<br>&#125;<br>processed_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files)<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="2-加载本地数据集"><a class="markdownIt-Anchor" href="#2-加载本地数据集"></a> 2. 加载本地数据集</h1>
<ul>
<li>Datasets 提供了加载本地数据集的方法。它支持几种常见的数据格式。对于每种数据格式，我们只需要在 <code>load_dataset()</code> 函数中指定数据的类型，并使用 data_files 指定一个或多个文件的路径的参数
<table>
<thead>
<tr>
<th>数据格式</th>
<th>类型参数</th>
<th>加载的指令</th>
</tr>
</thead>
<tbody>
<tr>
<td>CSV &amp; TSV</td>
<td>csv</td>
<td>load_dataset(&quot;csv&quot;, data_files=&quot;my_file.csv&quot;)</td>
</tr>
<tr>
<td>Text files</td>
<td>text</td>
<td>load_dataset(&quot;text&quot;, data_files=&quot;my_file.txt&quot;)</td>
</tr>
<tr>
<td>JSON &amp; JSON Lines</td>
<td>json</td>
<td>load_dataset(&quot;json&quot;, data_files=&quot;my_file.jsonl&quot;)</td>
</tr>
<tr>
<td>Pickled DataFrames</td>
<td>pandas</td>
<td>load_dataset(&quot;pandas&quot;, data_files=&quot;my_dataframe.pkl&quot;)</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h2 id="21-加载-csv-文件"><a class="markdownIt-Anchor" href="#21-加载-csv-文件"></a> 2.1 加载 csv 文件</h2>
<ul>
<li>
<p>首先准备 csv 文件 <code>ChnSentiCorp_htl_all.csv</code>，这是一个酒店评分数据，包含 label 和 review 两个字段</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cvs">    label,review<br>    1,&quot;距离川沙公路较近,但是公交指示不对,如果是&quot;&quot;蔡陆线&quot;&quot;的话,会非常麻烦.建议用别的路线.房间较为简单.&quot;<br>    1,商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!<br>    ...<br>- 利用多态实现，前文用于加载在线开源数据集的 `load_dataset` 方法也可以直接加载本地文件<br>    ```python<br>    from datasets import *<br>    <br>    # 直接加载默认得到一个 DatasetDict 对象，加载的数据集为其中的 &#x27;train&#x27; 数据集<br>    dataset = load_dataset(path=&#x27;csv&#x27;, data_files=f&#x27;./ChnSentiCorp_htl_all.csv&#x27;)<br>    dataset <br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [&#x27;label&#x27;, &#x27;review&#x27;],<br>        num_rows: 7766<br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 指定 split=&quot;train&quot; 加载，得到 Dataset 对象</span><br>dataset = load_dataset(<span class="hljs-string">&#x27;csv&#x27;</span>, data_files=<span class="hljs-string">f&#x27;./ChnSentiCorp_htl_all.csv&#x27;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)<br>dataset <br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">Dataset(&#123;<br>    features: [&#x27;label&#x27;, &#x27;review&#x27;],<br>    num_rows: 7766<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>可通过列表方式合并加载多个 .csv 文件</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_filepath_in_floder</span>(<span class="hljs-params">floder_path</span>):<br>    filepathes = os.listdir(floder_path)  <span class="hljs-comment"># 获取所有文件名称</span><br>    filepathes = [os.path.join(floder_path, file) <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> filepathes]<br>    <span class="hljs-keyword">return</span> filepathes<br><br><span class="hljs-comment"># 以列表形式加载多个 csv，会得到合并数据对应的 dataset</span><br>dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=get_filepath_in_floder(<span class="hljs-string">f&quot;./all_data&quot;</span>), split=<span class="hljs-string">&#x27;train&#x27;</span>)<br>dataset <br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">Dataset(&#123;<br>    features: [&#x27;label&#x27;, &#x27;review&#x27;],<br>    num_rows: 23298<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
<li>
<p><strong>可用类方法 <code>Dataset.from_csv()</code>  加载 csv 文件</strong>，效果和 <code>load_dataset</code> 等价</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset = Dataset.from_csv(<span class="hljs-string">f&quot;./ChnSentiCorp_htl_all.csv&quot;</span>)<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="22-加载-pandas-对象"><a class="markdownIt-Anchor" href="#22-加载-pandas-对象"></a> 2.2 加载 pandas 对象</h2>
<ul>
<li><strong>可用类方法 <code>Dataset.from_pandas()</code>  把 <code>pandas.core.frame.DataFrame</code> 直接转为 Dataset</strong>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>data = pd.read_csv(<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>)<br>dataset = Dataset.from_pandas(data)<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="23-加载-python-list-对象"><a class="markdownIt-Anchor" href="#23-加载-python-list-对象"></a> 2.3 加载 python list 对象</h2>
<ul>
<li>
<p><strong>可用类方法 <code>Dataset.from_list()</code>  把 python list 直接转为 Dataset</strong></p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># List格式的数据需要内嵌&#123;&#125;，明确数据字段</span><br>data = [&#123;<span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;abc&quot;</span>, <span class="hljs-string">&quot;label&quot;</span>: <span class="hljs-number">1</span>&#125;, &#123;<span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;def&quot;</span>, <span class="hljs-string">&quot;label&quot;</span>: <span class="hljs-number">2</span>&#125;]<br>Dataset.from_list(data)<br></code></pre></td></tr></table></figure>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">Dataset(&#123;<br>    features: [&#x27;text&#x27;, &#x27;label&#x27;],<br>    num_rows: 2<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="24-使用自定义数据加载脚本"><a class="markdownIt-Anchor" href="#24-使用自定义数据加载脚本"></a> 2.4 使用自定义数据加载脚本</h2>
<ul>
<li>本节我们处理一个具有复杂嵌套结构的 json 数据集 <code>cmrc2018_trial.json</code>，其由一系列问答段落组成  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;version&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;v1.0&quot;</span><span class="hljs-punctuation">,</span> <br>  <span class="hljs-attr">&quot;data&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;paragraphs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;TRIAL_800&quot;</span><span class="hljs-punctuation">,</span> <br>          <span class="hljs-attr">&quot;context&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;基于《跑跑卡丁车》与《泡泡堂》上所开发的游戏，由韩国Nexon开发与发行。中国大陆由盛大游戏运营，这是Nexon时隔6年再次授予盛大网络其游戏运营权。台湾由游戏橘子运营。玩家以水枪、小枪、锤子或是水炸弹泡封敌人(玩家或NPC)，即为一泡封，将水泡击破为一踢爆。若水泡未在时间内踢爆，则会从水泡中释放或被队友救援(即为一救援)。每次泡封会减少生命数，生命数耗完即算为踢爆。重生者在一定时间内为无敌状态，以踢爆数计分较多者获胜，规则因模式而有差异。以2V2、4V4随机配对的方式，玩家可依胜场数爬牌位(依序为原石、铜牌、银牌、金牌、白金、钻石、大师) ，可选择经典、热血、狙击等模式进行游戏。若游戏中离，则4分钟内不得进行配对(每次中离+4分钟)。开放时间为暑假或寒假期间内不定期开放，8人经典模式随机配对，采计分方式，活动时间内分数越多，终了时可依该名次获得奖励。&quot;</span><span class="hljs-punctuation">,</span> <br>          <span class="hljs-attr">&quot;qas&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;生命数耗完即算为什么？&quot;</span><span class="hljs-punctuation">,</span> <br>              <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;TRIAL_800_QUERY_0&quot;</span><span class="hljs-punctuation">,</span> <br>              <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-punctuation">&#123;</span><br>                  <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;踢爆&quot;</span><span class="hljs-punctuation">,</span> <br>                  <span class="hljs-attr">&quot;answer_start&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">127</span><br>                <span class="hljs-punctuation">&#125;</span><br>              <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span> <br>            <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;若游戏中离，则多少分钟内不得进行配对？&quot;</span><span class="hljs-punctuation">,</span> <br>              <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;TRIAL_800_QUERY_1&quot;</span><span class="hljs-punctuation">,</span> <br>              <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-punctuation">&#123;</span><br>                  <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;4分钟&quot;</span><span class="hljs-punctuation">,</span> <br>                  <span class="hljs-attr">&quot;answer_start&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">301</span><br>                <span class="hljs-punctuation">&#125;</span><br>              <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span> <br>            <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;玩家用什么泡封敌人？&quot;</span><span class="hljs-punctuation">,</span> <br>              <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;TRIAL_800_QUERY_2&quot;</span><span class="hljs-punctuation">,</span> <br>              <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-punctuation">&#123;</span><br>                  <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;玩家以水枪、小枪、锤子或是水炸弹泡封敌人&quot;</span><span class="hljs-punctuation">,</span> <br>                  <span class="hljs-attr">&quot;answer_start&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">85</span><br>                <span class="hljs-punctuation">&#125;</span><br>              <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span> <br>            <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;游戏的模式有哪些？&quot;</span><span class="hljs-punctuation">,</span> <br>              <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;TRIAL_800_QUERY_3&quot;</span><span class="hljs-punctuation">,</span> <br>              <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-punctuation">&#123;</span><br>                  <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;可选择经典、热血、狙击等模式进行游戏。&quot;</span><span class="hljs-punctuation">,</span> <br>                  <span class="hljs-attr">&quot;answer_start&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">275</span><br>                <span class="hljs-punctuation">&#125;</span><br>              <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><br>          <span class="hljs-punctuation">]</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <br>      <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;TRIAL_800&quot;</span><span class="hljs-punctuation">,</span> <br>      <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;泡泡战士&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span> <br>    ...<br></code></pre></td></tr></table></figure>
这个 json 可\直接 <code>load_dataset</code> 加载，通过 <code>filed</code> 形参指定要加载的字段  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># field 用于指定 json 文件中包含数据集的字段名</span><br>load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=<span class="hljs-string">&quot;./cmrc2018_trial.json&quot;</span>, field=<span class="hljs-string">&quot;data&quot;</span>)<br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [&#x27;paragraphs&#x27;, &#x27;id&#x27;, &#x27;title&#x27;],<br>        num_rows: 256<br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
<li>默认行为不符合预期，通过继承 <code>GeneratorBasedBuilder</code> 自定义 dataset builder，把段落中的问答对作为数据样本  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> DownloadManager, DatasetInfo<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CMRC2018TRIAL</span>(datasets.GeneratorBasedBuilder):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_info</span>(<span class="hljs-params">self</span>) -&gt; DatasetInfo:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">            info方法, 定义数据集的信息,这里要对数据的字段进行定义</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> datasets.DatasetInfo(<br>            description=<span class="hljs-string">&quot;CMRC2018 trial&quot;</span>,<br>            features=datasets.Features(&#123;<br>                    <span class="hljs-string">&quot;id&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),<br>                    <span class="hljs-string">&quot;context&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),<br>                    <span class="hljs-string">&quot;question&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),<br>                    <span class="hljs-string">&quot;answers&quot;</span>: datasets.features.<span class="hljs-type">Sequence</span>(<br>                        &#123;<br>                            <span class="hljs-string">&quot;text&quot;</span>: datasets.Value(<span class="hljs-string">&quot;string&quot;</span>),<br>                            <span class="hljs-string">&quot;answer_start&quot;</span>: datasets.Value(<span class="hljs-string">&quot;int32&quot;</span>),<br>                        &#125;<br>                    )<br>                &#125;)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_split_generators</span>(<span class="hljs-params">self, dl_manager: DownloadManager</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">            返回datasets.SplitGenerator</span><br><span class="hljs-string">            涉及两个参数: name和gen_kwargs</span><br><span class="hljs-string">            name: 指定数据集的划分</span><br><span class="hljs-string">            gen_kwargs: 指定要读取的文件的路径, 与_generate_examples的入参数一致</span><br><span class="hljs-string">        :param dl_manager:</span><br><span class="hljs-string">        :return: [ datasets.SplitGenerator ]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> [datasets.SplitGenerator(<br>            name=datasets.Split.TRAIN, <br>            gen_kwargs=&#123;<span class="hljs-string">&quot;filepath&quot;</span>: <span class="hljs-string">&quot;./cmrc2018_trial.json&quot;</span>&#125;)<br>        ]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_generate_examples</span>(<span class="hljs-params">self, filepath</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">            生成具体的样本, 使用yield</span><br><span class="hljs-string">            需要额外指定key, id从0开始自增就可以</span><br><span class="hljs-string">        :param filepath:</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># Yields (key, example) tuples from the dataset</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            data = json.load(f)<br>            <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> data[<span class="hljs-string">&quot;data&quot;</span>]:<br>                <span class="hljs-keyword">for</span> paragraph <span class="hljs-keyword">in</span> example[<span class="hljs-string">&quot;paragraphs&quot;</span>]:<br>                    context = paragraph[<span class="hljs-string">&quot;context&quot;</span>].strip()<br>                    <span class="hljs-keyword">for</span> qa <span class="hljs-keyword">in</span> paragraph[<span class="hljs-string">&quot;qas&quot;</span>]:<br>                        question = qa[<span class="hljs-string">&quot;question&quot;</span>].strip()<br>                        id_ = qa[<span class="hljs-string">&quot;id&quot;</span>]<br><br>                        answer_starts = [answer[<span class="hljs-string">&quot;answer_start&quot;</span>] <span class="hljs-keyword">for</span> answer <span class="hljs-keyword">in</span> qa[<span class="hljs-string">&quot;answers&quot;</span>]]<br>                        answers = [answer[<span class="hljs-string">&quot;text&quot;</span>].strip() <span class="hljs-keyword">for</span> answer <span class="hljs-keyword">in</span> qa[<span class="hljs-string">&quot;answers&quot;</span>]]<br><br>                        <span class="hljs-keyword">yield</span> id_, &#123;<br>                            <span class="hljs-string">&quot;context&quot;</span>: context,<br>                            <span class="hljs-string">&quot;question&quot;</span>: question,<br>                            <span class="hljs-string">&quot;id&quot;</span>: id_,<br>                            <span class="hljs-string">&quot;answers&quot;</span>: &#123;<br>                                <span class="hljs-string">&quot;answer_start&quot;</span>: answer_starts,<br>                                <span class="hljs-string">&quot;text&quot;</span>: answers,<br>                            &#125;,<br>                        &#125;<br></code></pre></td></tr></table></figure>
使用它加载数据集，需要在 <code>load_dataset</code> 的 <code>path</code> 形参传入加载脚本路径，并 <code>trust_remote_code</code>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset = load_dataset(<span class="hljs-string">&quot;./load_script.py&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>,  trust_remote_code=<span class="hljs-literal">True</span>)<br>dataset<br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">Dataset(&#123;<br>    features: [&#x27;id&#x27;, &#x27;context&#x27;, &#x27;question&#x27;, &#x27;answers&#x27;],<br>    num_rows: 1002<br>&#125;)<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="3-datacollector"><a class="markdownIt-Anchor" href="#3-datacollector"></a> 3. DataCollector</h1>
<ul>
<li>
<p>Transformers 库中，<strong><code>DataCollator</code> 是一个用于处理模型输入数据的实用工具。它通常用于将数据进行批处理、填充、截断或者任何其他处理</strong>。利用DataCollator，可以更方便地构造torch.utils.data.Dataloader，以便在训练模型时有效地处理输入数据。具体而言，DataCollator 的作用如下</p>
<ol>
<li><strong>批处理处理</strong>: 将输入数据按照模型的要求组合成 batch，以便进行训练</li>
<li><strong>填充与截断</strong>: 通过填充和截断处理不同长度的输入数据。这对于需要固定长度的模型输入非常重要</li>
<li><strong>特殊处理</strong>: 在某些情况下，为了满足模型输入的特殊要求，DataCollator 可能需要进行特殊处理，比如添加特殊的标记或者标签</li>
</ol>
</li>
<li>
<p><strong>DataCollator 只能自动处理 hf 格式的数据，限于以下字段，当自定义数据很复杂不止这些字段时，不建议使用</strong></p>
<ul>
<li><code>'input_ids'</code></li>
<li><code>'token_type_ids'</code></li>
<li><code>'attention_mask'</code></li>
<li><code>'labels'</code></li>
</ul>
</li>
<li>
<p>不使用 Dataset 库时，我们使用 Pytorch 原生的 Dataset 和 Dataloader 进行数据集构造。<strong>需定义 <code>collate_func()</code> 对 dataloader 得到的 batch data 进行后处理</strong></p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 不用 DataCollator 时，从 ChnSentiCorp_htl_all 数据构造 Dataloader 的方法如下</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader, random_split<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.data = pd.read_csv(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;os.getcwd()&#125;</span>/ChnSentiCorp_htl_all.csv&quot;</span>)    <span class="hljs-comment"># 加载原始数据</span><br>        <span class="hljs-variable language_">self</span>.data = <span class="hljs-variable language_">self</span>.data.dropna()                                        <span class="hljs-comment"># 去掉脏数据, 去掉 nan 值</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        text:<span class="hljs-built_in">str</span> = <span class="hljs-variable language_">self</span>.data.iloc[index][<span class="hljs-string">&quot;review&quot;</span>]<br>        label:<span class="hljs-built_in">int</span> = <span class="hljs-variable language_">self</span>.data.iloc[index][<span class="hljs-string">&quot;label&quot;</span>]<br>        <span class="hljs-keyword">return</span> text, label<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.data)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_func</span>(<span class="hljs-params">batch</span>):<br>    <span class="hljs-comment"># 对 dataloader 得到的 batch data 进行后处理</span><br>    <span class="hljs-comment"># batch data 是一个 list，其中每个元素是 (sample, label) 形式的元组</span><br>    texts, labels = [], []<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> batch:<br>        texts.append(item[<span class="hljs-number">0</span>])<br>        labels.append(item[<span class="hljs-number">1</span>])<br>    <br>    <span class="hljs-comment"># 对原始 texts 列表进行批量 tokenize，通过填充或截断保持 token 长度为 128，要求返回的每个字段都是 pytorch tensor</span><br>    <span class="hljs-keyword">global</span> tokenizer<br>    inputs = tokenizer(texts, max_length=<span class="hljs-number">128</span>, padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br><br>    <span class="hljs-comment"># 增加 label 字段</span><br>    inputs[<span class="hljs-string">&quot;labels&quot;</span>] = torch.tensor(labels)<br>    <span class="hljs-keyword">return</span> inputs<br><br><br><span class="hljs-comment"># 构造 torch.utils.data.Dataset，划分训练和测试集</span><br>dataset = MyDataset()<br>train_size = <span class="hljs-built_in">int</span>(<span class="hljs-number">0.9</span>*<span class="hljs-built_in">len</span>(dataset))<br>vaild_size = <span class="hljs-built_in">len</span>(dataset) - train_size<br>trainset, validset = random_split(dataset, lengths=[train_size, vaild_size])<br><br><span class="hljs-comment"># 构造 torch.utils.data.Dataloader，在 collate_func 中批量后处理（tokenize、truncation、padding）</span><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;hfl/rbt3&quot;</span>)<br>trainloader = DataLoader(trainset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>, collate_fn=collate_func)<br>validloader = DataLoader(validset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">False</span>, collate_fn=collate_func)<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>使用 Dataset 库的 Dataset 和 DataCollector 可以更简洁地实现</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用 DataCollator 完成同样的任务</span><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding   <span class="hljs-comment"># 该 Collator 会动态地对输入进行 padding 操作</span><br><br><span class="hljs-comment"># 数据加载 &amp; 清洗</span><br>dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)<br>dataset = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;review&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>)<br><br><span class="hljs-comment"># 批量预处理（tokenize &amp; truncation，不做 padding）得到 datasets.arrow_dataset.Dataset</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_function</span>(<span class="hljs-params">examples, tokenizer</span>):<br>    tokenized_examples = tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], max_length=<span class="hljs-number">128</span>, truncation=<span class="hljs-literal">True</span>)<br>    tokenized_examples[<span class="hljs-string">&quot;labels&quot;</span>] = examples[<span class="hljs-string">&quot;label&quot;</span>]<br>    <span class="hljs-keyword">return</span> tokenized_examples<br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;hfl/rbt3&quot;</span>)<br>tokenized_dataset = dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> examples: process_function(examples, tokenizer), batched=<span class="hljs-literal">True</span>, remove_columns=dataset.column_names)<br><br><span class="hljs-comment"># 划分训练/测试集</span><br>datasets = tokenized_dataset.train_test_split(test_size=<span class="hljs-number">0.1</span>)<br>trainset, validset = datasets[<span class="hljs-string">&#x27;train&#x27;</span>], datasets[<span class="hljs-string">&#x27;test&#x27;</span>]<br><br><span class="hljs-comment"># 定义 collator 对象，将其作为 collate_fn 定义 torch.utils.data.Dataloader</span><br>collator = DataCollatorWithPadding(tokenizer=tokenizer)<br>trainloader = DataLoader(trainset, batch_size=<span class="hljs-number">4</span>, shuffle=<span class="hljs-literal">True</span>, collate_fn=collator)<br>validloader = DataLoader(validset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">False</span>, collate_fn=collator)<br></code></pre></td></tr></table></figure>
<p>注意这里我们设置 <code>tokenizer(examples[&quot;review&quot;], max_length=128, truncation=True)</code> 并使用了 <code>DataCollatorWithPadding</code>，这会自动把 batch 中 <code>input_ids</code> 右侧 zero-padding 到 batch 内最大长度，并将所有长度超过 128 的序列截断到 128</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 取 10 个 batch，观察 padding 长度</span><br><span class="hljs-keyword">for</span> i, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader):<br>    <span class="hljs-built_in">print</span>(batch[<span class="hljs-string">&quot;input_ids&quot;</span>].size())<br>    <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">10</span>:<br>        <span class="hljs-keyword">break</span><br><br>‘’‘<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">74</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">87</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">128</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">128</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">128</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">128</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">127</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">128</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">128</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">128</span>])<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">128</span>])<br>‘’’<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="4-最佳实践"><a class="markdownIt-Anchor" href="#4-最佳实践"></a> 4. 最佳实践</h1>
<ul>
<li>
<p>使用 IMDb 小型评论数据集的子集进行全流程实践，包括：</p>
<ol>
<li>用 <code>load_dataset()</code> 加载数据，使用 <code>dataset.shuffle()</code> 打乱并用  <code>dataset.select()</code> 提取子集</li>
<li>用 <code>dataset.map()</code> 和 <code>dataset.filter()</code> 清洗数据</li>
<li>用 <code>dataset.map()</code> 补充特征</li>
<li>创建 <code>AutoTokenizer</code>，用 <code>dataset.map(tokenize_function, batched=True)</code> 进行高效批量分词</li>
<li>用 <code>DataCollatorWithPadding</code> 动态填充</li>
<li>构造可直接用于训练的 <code>DataLoader</code></li>
</ol>
</li>
<li>
<p>示例代码如下</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, DatasetDict<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> html<br><br><span class="hljs-comment"># =============================================</span><br><span class="hljs-comment"># 1. 加载数据（使用 Hugging Face 官方 IMDb 小样本）</span><br><span class="hljs-comment"># =============================================</span><br>raw_datasets = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>)<br><br><span class="hljs-comment"># 为了演示，随机抽样 200 条训练 + 100 条测试</span><br>small_train = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>))<br>small_test = raw_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;✅ 原始样本示例：&quot;</span>)<br><span class="hljs-built_in">print</span>(small_train[<span class="hljs-number">0</span>], <span class="hljs-string">&quot;\n&quot;</span>)<br><br><span class="hljs-comment"># =============================================</span><br><span class="hljs-comment"># 2. 清洗文本</span><br><span class="hljs-comment"># =============================================</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">clean_text</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-comment"># HTML 转义解码 + 小写化</span><br>    text = html.unescape(example[<span class="hljs-string">&quot;text&quot;</span>]).replace(<span class="hljs-string">&quot;&lt;br /&gt;&quot;</span>, <span class="hljs-string">&quot; &quot;</span>).lower()<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;text&quot;</span>: text&#125;<br><br>small_train = small_train.<span class="hljs-built_in">map</span>(clean_text).<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x[<span class="hljs-string">&quot;text&quot;</span>]) &gt; <span class="hljs-number">30</span>)<br>small_test = small_test.<span class="hljs-built_in">map</span>(clean_text).<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x[<span class="hljs-string">&quot;text&quot;</span>]) &gt; <span class="hljs-number">30</span>)<br><br><span class="hljs-comment"># =============================================</span><br><span class="hljs-comment"># 3. 增加特征列（Feature Engineering）</span><br><span class="hljs-comment">#   - 字符长度</span><br><span class="hljs-comment">#   - 词数</span><br><span class="hljs-comment">#   - 平均词长</span><br><span class="hljs-comment"># =============================================</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_features</span>(<span class="hljs-params">example</span>):<br>    text = example[<span class="hljs-string">&quot;text&quot;</span>]<br>    words = text.split()<br>    char_len = <span class="hljs-built_in">len</span>(text)<br>    word_len = <span class="hljs-built_in">len</span>(words)<br>    avg_word_len = <span class="hljs-built_in">sum</span>(<span class="hljs-built_in">len</span>(w) <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> words) / (word_len + <span class="hljs-number">1e-8</span>)<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&quot;char_len&quot;</span>: char_len,<br>        <span class="hljs-string">&quot;word_len&quot;</span>: word_len,<br>        <span class="hljs-string">&quot;avg_word_len&quot;</span>: avg_word_len,<br>    &#125;<br><br>small_train = small_train.<span class="hljs-built_in">map</span>(add_features)<br>small_test = small_test.<span class="hljs-built_in">map</span>(add_features)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;✅ 数据列：&quot;</span>, small_train.column_names)    <span class="hljs-comment"># [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;char_len&#x27;, &#x27;word_len&#x27;, &#x27;avg_word_len&#x27;]</span><br><br><span class="hljs-comment"># =============================================</span><br><span class="hljs-comment"># 4. Tokenization（不做 padding）</span><br><span class="hljs-comment"># =============================================</span><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):<br>    tokenized = tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>], truncation=<span class="hljs-literal">True</span>, max_length=<span class="hljs-number">128</span>)<br>    tokenized[<span class="hljs-string">&quot;labels&quot;</span>] = examples[<span class="hljs-string">&quot;label&quot;</span>]<br>    <span class="hljs-comment"># 保留数值特征列</span><br>    tokenized[<span class="hljs-string">&quot;char_len&quot;</span>] = examples[<span class="hljs-string">&quot;char_len&quot;</span>]<br>    tokenized[<span class="hljs-string">&quot;word_len&quot;</span>] = examples[<span class="hljs-string">&quot;word_len&quot;</span>]<br>    tokenized[<span class="hljs-string">&quot;avg_word_len&quot;</span>] = examples[<span class="hljs-string">&quot;avg_word_len&quot;</span>]<br>    <span class="hljs-keyword">return</span> tokenized<br><br>tokenized_train = small_train.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>, remove_columns=[<span class="hljs-string">&quot;text&quot;</span>])<br>tokenized_test = small_test.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>, remove_columns=[<span class="hljs-string">&quot;text&quot;</span>])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;✅ Tokenized 示例：&quot;</span>)<br><span class="hljs-built_in">print</span>(tokenized_train[<span class="hljs-number">0</span>].keys(), <span class="hljs-string">&quot;\n&quot;</span>)<br><br><span class="hljs-comment"># =============================================</span><br><span class="hljs-comment"># 5. 构造 DataCollator &amp; Dataloader</span><br><span class="hljs-comment"># =============================================</span><br>collator = DataCollatorWithPadding(tokenizer=tokenizer)<br><br>train_loader = DataLoader(tokenized_train, batch_size=<span class="hljs-number">8</span>, shuffle=<span class="hljs-literal">True</span>, collate_fn=collator)<br>valid_loader = DataLoader(tokenized_test, batch_size=<span class="hljs-number">8</span>, shuffle=<span class="hljs-literal">False</span>, collate_fn=collator)<br><br><span class="hljs-comment"># 查看 batch 样例</span><br>batch = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(train_loader))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;✅ 一个 batch 的字段：&quot;</span>)<br><span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items():<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(v, torch.Tensor):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;k:&lt;<span class="hljs-number">15</span>&#125;</span> -&gt; shape <span class="hljs-subst">&#123;<span class="hljs-built_in">tuple</span>(v.shape)&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;k:&lt;<span class="hljs-number">15</span>&#125;</span> -&gt; type <span class="hljs-subst">&#123;<span class="hljs-built_in">type</span>(v)&#125;</span>&quot;</span>)<br><br><br></code></pre></td></tr></table></figure>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">✅ 原始样本示例：<br>&#123;&#x27;text&#x27;: &#x27;There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\&#x27;s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have &quot;clairvoyance&quot;. People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\&#x27;s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...&#x27;, &#x27;label&#x27;: 1&#125; <br><br>✅ 数据列： [&#x27;text&#x27;, &#x27;label&#x27;, &#x27;char_len&#x27;, &#x27;word_len&#x27;, &#x27;avg_word_len&#x27;]<br><br>✅ Tokenized 示例：<br>dict_keys([&#x27;label&#x27;, &#x27;char_len&#x27;, &#x27;word_len&#x27;, &#x27;avg_word_len&#x27;, &#x27;input_ids&#x27;, &#x27;token_type_ids&#x27;, &#x27;attention_mask&#x27;, &#x27;labels&#x27;]) <br><br>✅ 一个 batch 的字段：<br>char_len        -&gt; shape (8,)<br>word_len        -&gt; shape (8,)<br>avg_word_len    -&gt; shape (8,)<br>input_ids       -&gt; shape (8, 128)<br>token_type_ids  -&gt; shape (8, 128)<br>attention_mask  -&gt; shape (8, 128)<br>labels          -&gt; shape (8,)<br></code></pre></td></tr></table></figure>
</li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/MyBlog/categories/%E5%B8%B8%E7%94%A8%E5%BA%93/" class="category-chain-item">常用库</a>
  
  
    <span>></span>
    
  <a href="/MyBlog/categories/%E5%B8%B8%E7%94%A8%E5%BA%93/Transformers%E5%BA%93/" class="category-chain-item">Transformers库</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/MyBlog/tags/Transformers%E5%BA%93/" class="print-no-link">#Transformers库</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Transformess库（5）—— Datasets</div>
      <div>https://wxc971231.github.io/MyBlog/2025/10/08/Transformess库5_Datasets/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>云端fff</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月8日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/MyBlog/2025/10/16/%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3LLM_%E5%9B%9E%E5%BD%92_NTLRegressDontGuess__ARegression_likeLossonNumberTokensforLanguageModel/" title="论文理解【LLM-回归】——【NTL】Regress, Don‘t Guess--A Regression-like Loss on Number Tokens for Language Model">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">论文理解【LLM-回归】——【NTL】Regress, Don‘t Guess--A Regression-like Loss on Number Tokens for Language Model</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/MyBlog/2025/10/03/Transformers%E5%BA%934_Model/" title="Transformers库（4）—— Model">
                        <span class="hidden-mobile">Transformers库（4）—— Model</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/MyBlog/js/events.js" ></script>
<script  src="/MyBlog/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/MyBlog/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/MyBlog/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/MyBlog/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
